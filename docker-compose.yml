version: "3.9"

services:
  redis:
    image: redis:alpine
    restart: always

  backend:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      # Mount local directories for uploads and generated images
      - ./app/uploads:/app/app/uploads
      - ./app/generated:/app/app/generated
      # Mount a named volume for Hugging Face model cache
      - hf_cache:/root/.cache/huggingface
    environment:
      - PYTHONUNBUFFERED=1
      - HF_HOME=/root/.cache/huggingface
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - redis
    # No GPU needed for the API server itself
    restart: always

  worker:
    build:
      context: .
      dockerfile: Dockerfile
    command: celery -A app.worker.celery_app worker --loglevel=info -c 1
    volumes:
      # Worker needs access to uploads to read sketches
      - ./app/uploads:/app/app/uploads
      # Worker needs access to generated to save images
      - ./app/generated:/app/app/generated
      # Worker needs access to the model cache
      - hf_cache:/root/.cache/huggingface
    environment:
      - PYTHONUNBUFFERED=1
      - HF_HOME=/root/.cache/huggingface
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - redis
    # Add NVIDIA runtime configuration for GPU access for the worker
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all # Use all available GPUs, or specify indices e.g., [0, 1]
              capabilities: [gpu]
    restart: always

# Define the named volume for the cache
volumes:
  hf_cache:

